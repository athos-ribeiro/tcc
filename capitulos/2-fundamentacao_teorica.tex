\chapter{Fundamentação Teórica}\label{fundamentacao_teorica}

Este capitulo contextualiza o presente trabalho, apresentando definições de conceitos que serão utilizados em outros capítulos. Inicialmente define-se análise estática de código fonte e apresentam-se exemplos métricas para um contexto de segurança. Em seguida, são apresentadas algumas ferramentas para análise estática, bem como a definição exemplos de bases de dados de vulnerabilidades. Por fim, discutem-se trabalhos relacionados à análise estática de segurança de código fonte e avaliações deste tipo de ferramenta.

\section{Análise Estática de Código}\label{fundamentacao_teorica:analise_estatica_de_codigo}

Metade dos defeitos de segurança de software são introduzidos à nível de código-fonte \cite{vadim}. Em tal contexto, software pode ser verificado através da análise dinâmica ou da análise estática \cite{concolic}.

Técnicas de análise dinâmica são baseadas na análise de software realizada através da execução do programa analisado, em um processador real ou virtual \cite{concolic}, e podem encontrar defeitos ao longo da fase de testes. Mas para tal necessitam que o código esteja em um estado em que possa ser executado e instalado. Além disso, apenas os defeitos que se encontram no caminho de execução que as entradas dos testes fornecem podem ser encontrados \cite{harvard}.

Análise estática de código é a análise de programas de computador sem a necessidade de executar tais programas, geralmente feita por ferramentas externas, de forma automatizada \cite{kannavara}. À tais ferramentas dá-se o nome de ferramenta de análise estática de código fonte, ou simplesmente ferramenta de análise estática. Segundo \cite{secure_programming}, qualquer ferramenta que analisa código sem o executar está realizando análise estática de código.

Ferramentas de análise estática podem inferir informações  acerca de um software sem a necessidade de executar o mesmo, tornando-as ferramentas adequadas para detecção de fraquezas no código \cite{vadim}. Deste modo, tais ferramentas se mostram um ponto razoável para que se possa buscar maior qualidade final do software \cite{sa_spec}.

\textbf{Fraquezas} são defeitos de software provenientes do design, implementação ou outras áreas do ciclo de desenvolvimento do software. Em condições específicas, fraquezas podem contribuir para a introdução de \textbf{vulnerabilidades} no software. Quando ativadas, estas vulnerabilidades (manifestações de fraquezas) resultam em falhas de sistema, ou simplesmente falhas.
\begin{citacao}
Muitas vezes os termos fraqueza e vulnerabilidade são confundidos ou as pessoas discordam de suas definições. As ferramentas de análise estática buscam por fraquezas no código, quando as pessoas, em grande parte das vezes, gostariam que elas buscassem por vulnerabilidades\footnote{por Steven M. Christey, engenheiro de segurança da informação do MITRE em uma lista de discussão sobre segurança web disponível em \url{http://lists.webappsec.org/pipermail/websecurity_lists.webappsec.org/2011-November/008118.html}}.
\end{citacao}

O MITRE é uma organização sem fins lucrativos que opera centros de pesquisa e desenvolvimento patrocinados pelo governo federal dos Estados Unidos da América. Uma das iniciativas do MITRE, patrocinada por um projeto de métricas de qualidade de software e avaliação de ferramentas (SAMATE - Software Assurance Metrics and Tool Evaluation), visa elaborar e manter um catálogo de fraquezas de software, onde as fraquezas de software conhecidas recebem uma definição formal e um número identificador. Tal catálogo de fraquezas é conhecido como Common Weakness Enumeration ou CWE\footnote{\url{cwe.mitre.org}}, e tem sido amplamente adotado para referenciar fraquezas de software, tanto na indústria quanto na academia.

Consideraremos fraquezas de software apenas os defeitos que estiverem mapeadas como fraquezas em forma de CWE. Sendo assim, chamaremos de defeito (ou \textit{bug}) as fraquezas do software.

Existem diferentes técnicas de análise estática de código-fonte, que variam desde simples análises léxicas, análises de fluxo de dados à análise de grafos de fluxo de controle. Ao apontar defeitos no código, uma ferramenta de análise estática pode ou não cometer erros quando analisando determinado trecho de código, dada a natureza do defeito ali presente (ou ausência de defeitos) e à técnica de análise empregada. Algumas técnicas são menos sofisticadas e estão mais suscetíveis a erros do que outras \cite{harvard}. Ainda assim, cada uma das técnicas de análise estática tem suas limitações \cite{pascal}, o que justifica o uso de e a busca por diferentes técnicas de análise.

Conforme a terminologia utilizada em \cite{sa_spec}, chama-se \textbf{falso positivo}, ou alarme falso, um trecho de código apontado como defeituoso por uma ferramenta de análise estática que, na verdade, não se trata de um defeito, ou seja, a ferramenta cometeu um erro ao apontar um trecho de código não defeituoso como defeituoso. Chama-se \textbf{falso negativo} um defeito no código fonte, que se enquadra na categoria de defeitos detectados pela ferramenta que analisa o código em questão, que não foi detectado pela ferramenta, ou seja, a ferramenta cometeu um erro ao não apontar um trecho de código defeituoso.

Uma ferramenta ideal não cometeria erros, apontando todos os defeitos do código (mesmo que apenas em uma dada categoria) e nunca apontando um trecho de código correto como defeituoso (a ferramenta não comete falsos positivos nem falsos negativos). Trabalhos anteriores mostram que é impossível, mesmo em teoria, produzir tal ferramenta \cite{sa_spec} devido ao Teorema de Rice \cite{rice}, que prova que para qualquer propriedade de software que não seja trivial, não existe algoritmo capaz de decidir se um programa qualquer possui tal propriedade, de modo que buscam-se aproximações para a solução de problemas ou tomadas de decisões relacionadas à análise estática. É possível, porém, produzir ferramentas capazes de cometer apenas um dos tipos de erro (falsos positivos ou falsos negativos). À análise estática que não gera falsos negativos, ou seja, aponta todos os defeitos no código, embora aponte alguns trechos como defeituosos quando os mesmos não são defeitos de fato (ou seja, gera falsos positivos) mas sem deixar de apontar nenhum defeito real, chamamos \textbf{análise correta}. À análise estática que não gera falsos positivos, ou seja, todos os possíveis defeitos apontados por ela são de fato trechos de código defeituosos, embora deixe de apontar alguns defeitos presentes no código (ou seja, gera falsos negativos), chama-se \textbf{análise completa}. Por fim, pode-se relacionar os termos com os Teoremas de Incompletude \cite{godel}, de modo que não é possível realizar uma análise completa e correta.

\section{Métricas e Métricas de Segurança}

Em \cite{nsa}, o CAS (Center for Assured Software) da Agência de Segurança Nacional (NSA – National Security Agency), centro de pesquisa criado para aumentar o nível de confiança de que os software utilizados pelo Departamento de Defesa dos Estados Unidos (DoD – Department of Defense) estão livres de vulnerabilidades \cite{nsa}, apresenta um conjunto de métricas para que se aplique sua metodologia. Das métricas apresentadas, algumas são de propósito geral, ou seja, independentes da natureza da suíte de testes ou mesmo da metodologia de testes empregada na análise, desde que sejam conhecidos todos os defeitos presentes no código a ser analisado. Ao realizar seu \textit{workshop} de avaliação de ferramentas, o SATE, o NIST utiliza este conjunto de métricas descrito pelo CAS para suas análises, como notado em \cite{sate_iv}. Essas métricas são:
\begin{description}
    \item[Positivos:] Quantidade total de defeitos reportados pela ferramenta que são de fato defeitos no código-fonte analisado.

    \item[Falsos Positivos:] Quantidade total de defeitos reportados pela ferramenta que não são defeitos no código-fonte analisado.

    \item[Falsos Negativos:] Quantidade de defeitos presentes no código fonte que não foram reportados pela ferramenta.

      Note que o conjunto que contém todos os Positivos e todos os Falsos Negativos, é o conjunto de todos os defeitos presentes no código-fonte. Tal conceito foi amplamente utilizado para as análises da \textit{Ockham Criteria}\footnote{\url{http://samate.nist.gov/SATE5OckhamCriteria.html}} realizada na quinta edição do SATE\footnote{\url{http://samate.nist.gov/SATE5.html}}, pelo NIST, cujos resultados ainda não foram publicados. Chamaremos tal conjunto de Trechos Defeituosos, (Equação \eqref{eq1}),
\begin{equation}\label{eq1}
TD = P + FN,
\end{equation}
  onde $TD$ é o número de Trechos Defeituosos, $P$ o número de Positivos e $FN$ o número de Falsos Negativos.

  No contexto da \textit{Ockham Criteria} do SATE V do NIST, considera-se um defeito apenas se o mesmo for uma fraqueza, ou seja, um defeito só é considerado quando formalizado de acordo com o CWE, como mencionado   na Seção \nameref{fundamentacao_teorica:analise_estatica_de_codigo} do presente trabalho. Isso implica que a Equação \eqref{eq1} pode não ser verdadeira, dado que podem existir defeitos reportados pela ferramenta que não estejam mapeados em forma de CWE, ou ainda, que estejam sujeitos à interpretação das CWE, que como mencionado em \cite{yan} e notado ao longo dos trabalhos  da \textit{Ockham Criteria}, nem sempre são definidas com precisão.

\item[Precisão:] Número de defeitos reais reportados dividido pelo número total de defeitos reportados, que inclui os não-defeitos incorretamente reportados como defeitos ($FP$).  Ela pode ser representada pela Equação \eqref{eq2},
\begin{equation}\label{eq2}
  P_r = \frac{P}{P + FP}
\end{equation}
  onde $P_r$ é a precisão, $P$ o número de Positivos e $FP$ o número de Falsos Positivos.

  A precisão indica a capacidade da ferramenta de identificar defeitos. Note que a precisão é indefinida quando uma ferramenta não reporta erros \cite{nsa}, pois $P = 0$, e $FP = 0$, de modo que $P_r = \frac{0}{0}$. Quando definida, $0 \leq Pr \leq 1$.

\item[Corretude:] Corresponde à fração de defeitos reais reportados pela ferramenta. É definida como o número de defeitos reais reportados dividido pelo número total de defeitos existentes no código, que inclui os defeitos reais que não foram reportados ($FN$), conforme apresenta a Equação \eqref{eq3},
\begin{equation}\label{eq3}
  C_r = \frac{P}{P + FN},
\end{equation}
  onde $C_r$ é a Corretude, $P$ o número de positivos e $FN$ o número de falsos negativos, ou, em casos onde a Equação \eqref{eq1} for verdadeira, de acordo com a Equação \eqref{eq4}.
\begin{equation}\label{eq4}
  C_r = \frac{P}{TD}.
\end{equation}

  Valores altos de corretude indicam que a ferramenta identifica grande parte dos defeitos corretamente. Note que $0 \leq C_r \leq 1$.

  Uma ferramenta que apresenta Corretude igual a 1 (um) na maior parte das análise é, possivelmente, uma ferramenta de análise estática correta. Uma ferramenta é considerada não correta se sua Corretude  menor do que 1 para uma dada análise.

  \item[F-score:] Média harmônica da Correção e Precisão. O F-score auxilia no julgamento de uma ferramenta de análise estática verificando a quantidade de defeitos capturados e quanto ruído foi gerado no processo (falsos positivos). Utiliza-se a media harmônica de modo a prover pontuação justa para ferramentas que com bons resultados tanto para Corretude quanto para Precisão (Uma ferramenta com Corretude alta e Precisão baixa não teria melhores resultados que uma ferramenta mediana para ambas as métricas). O cálculo do F-score é apresentado na Equação \eqref{eq5},
\begin{equation}\label{eq5}
  F_s = 2\left(\frac{P \times C_r}{P + C_r}\right)
\end{equation}
onde $F_s$ é o F-score, $P$ a precisão e $C_r$ a Corretude.
\end{description}

  Existem outras métricas que são relevantes apenas para análises que utilizem suítes de teste como a proposta pelo CAS em \cite{nsa}, também descrita em \cite{juliet}. A mesma se trata de uma suíte de testes composta de casos de teste artificiais ou sintéticos, que são definidos posteriormente, na Seção \nameref{fundamentacao_teorica:bases_de_testes_de_vulnerabilidades}.

  \section{Ferramentas de Análise Estática de Código}

  Existem diversas ferramentas para análise estática de código-fonte. Algumas delas se especializam em diversos tipos de análise, dificultando qualquer esforço de classificá-las como ferramentas voltadas à segurança de código-fonte ou não. O grupo de trabalho SAMATE do  NIST mantém uma lista com ferramentas de análise estática voltada à segurança. Esta lista é de acesso público, irrestrito e pode ser acessada em \url{http://samate.nist.gov/index.php/Source_Code_Security_Analyzers.html}. Embora a lista seja aberta, a mesma inclui ferramentas de diferentes licenças, onde algumas são Livres\footnote{O conceito de Software Livre é formalmente definido em \url{https://www.gnu.org/philosophy/free-sw.html}} e outras, proprietárias, de modo que nem todas as ferramentas estão facilmente disponíveis para uso, testes ou avaliações.

  Note que compiladores que indicam \textit{warnings} ao longo do processo de compilação estão indicando possíveis defeitos que podem levar a vulnerabilidades, de modo que tais compiladores podem ser considerados ferramentas de análise estática no presente contexto.


  \section{Bases de Testes de Vulnerabilidades}\label{fundamentacao_teorica:bases_de_testes_de_vulnerabilidades}

  Para que se possam avaliar ferramentas de análise estática de código fonte, é necessário que se possua o software à disposição para que as ferramentas sob avaliação possam analisá-lo \cite{nsa}. Ao software utilizado para avaliação de ferramentas de análise estática dá-se o nome de \textbf{caso de teste}. Um conjunto de casos de teste é chamado de \textbf{suíte de testes}.

  Conforme \cite{nsa}, existem dois tipos de caso de teste: \textbf{caso de teste natural}, quando utiliza-se um software qualquer, de propósito qualquer, como caso de teste para ferramentas de análise estática e \textbf{casos de teste artificial}, ou como chamados em \cite {juliet}, caso de teste sintético, quando estes são criados especificamente para testar ferramentas de análise estática de código fonte.

  Para gerar casos de teste sintéticos é necessário que se insiram defeitos no código de forma proposital. Isto facilita a avaliação da ferramenta, uma vez que a localização de todos os defeitos do código a ser analisado, bem como sua natureza, são conhecidas\footnote{Exceto quando, como mencionado em \cite{pascal}, existam bugs no próprio caso de teste}. Casos de teste naturais são nada mais que o código fonte de software qualquer. Estes podem ser facilmente obtidos graças às licenças de Software Livre como a \textit{GNU General Public License} (GPL),  na qual um de seus termos implica na distribuição do código-fonte juntamente com os executáveis\footnote{\url{http://www.gnu.org/licenses/gpl-3.0.en.html}}.

  Há ainda \textbf{casos de teste híbridos}, onde injetam-se defeitos em software conhecidos para que se possa aumentar o grau de complexidade do caso de teste (que é baixo em casos de teste artificiais) mantendo um maior controle sob os defeitos presentes no código (que é baixo em casos de teste naturais). Um exemplo de casos de teste híbridos é a suíte de testes STONESOUP (\textit{Securely Taking On New Executable Software of Uncertain Provenance}), onde a IARPA (\textit{Intelligence Advanced Research Projects Activity}) juntamente com uma empresa contratada selecionou alguns software de licenças livres como grep\footnote{\url{https://www.gnu.org/software/grep/}} e injetaram diversas CWE em seus códigos-fonte, gerando uma Suíte de Testes com mais de 7.000 Casos de Teste. Embora o projeto tenha sido iniciado com um objetivo diferente\footnote{Para mais detalhes sobre o projeto STONESOUP, ver \url{http://www.iarpa.gov/index.php/research-programs/stonesoup}}, os casos de testes gerados foram transferidos para o NIST, de modo que o mesmo pudesse disponibilizá-los ao público.

  Ao se selecionar o tipo de caso de teste a ser utilizado devem-se considerar os objetivos da avaliação em questão. Kratkiewicz \cite{harvard} propõe que uma ferramenta de análise estática verdadeiramente útil deve ter uma boa taxa de detecção de defeitos quando  analisar programas grandes do mundo real\footnote{Infere-se aqui que um programa grande seja qualquer software de código não trivial e um programa do mundo real seja qualquer software utilizado em produção que gere algum valor ao usuário final}. O autor ainda sugere que a não detecção de um defeito específico em um caso de teste sintético por uma ferramenta de análise estática implica na não detecção (a partir de análise com a mesma ferramenta de análise estática) de um defeito similar em um código mais complexo, do mundo real (visto que o primeiro trata-se de um caso pontual, simplificado). Porém, não pode-se afirmar que, caso tal defeito seja detectado no caso de teste sintético, um defeito similar a ele também será detectado no código mais complexo, de mundo real (fato que remete ao Teorema de Rice \cite{rice} quando à impossibilidade de descrever comportamentos não-triviais de programas, e que pode ser justificado ao afirmar que análise estática trabalha com aproximações). Por fim \cite{harvard} afirma que um caso de testes deve ser estruturado de modo a prover informações precisas quanto a detecção, falsos positivos e casos em que a ferramenta se confunde. Para o último cenário, apontam-se casos de testes com duas versões do mesmo código, onde uma delas possui um defeito e a outra não.

  Pascal Cuoq \cite{pascal} afirma que um caso de teste deve possuir no máximo um comportamento indefinido\footnote{entenda por defeito}, dado que com mais de um comportamento indefinido em um caso de teste, pode haver mal julgamento da ferramenta de análise estática, como no caso de a ferramenta terminar sua execução em determinado fluxo de dados ao encontrar um defeito crítico no mesmo. Neste caso, um defeito inserido posteriormente sequer seria analisado. Sendo assim, nota-se que Pascal Cuoq nitidamente sugere que se usem casos de teste sintéticos, mas alerta que os mesmos não são capazes de medir o quão bem um programa de análise estática se sairia em produção, dado que neste caso tem-se um ambiente menos controlado, com inúmeras possibilidades de entrada de uma só vez.

  Existem algumas iniciativas para coletar e redistribuir casos de testes para análise estática de código fonte, de modo a auxiliar pesquisadores e estudantes interessados em análise estática, bem como proporcionar bases de testes para desenvolvedores de ferramentas de análise estática de modo a melhorar a qualidade deste tipo de software. Dentre tais iniciativas, destacam-se dois programas norte americanos, o SARD  – \textit{Software Assurance Reference Dataset}, anteriormente conhecido como SRD – \textit{SAMATE Reference Dataset}\footnote{O SARD teve seu nome alterado em 2014, pois o NIST, seu mantenedor, já possui um outro projeto com o nome de SRD}, que visa disponibilizar casos e suítes de testes para estudo de fraquezas e vulnerabilidades de software, para que indústria e academia possam melhor entendê-los, conduzir estudos e produzir ferramentas com maior qualidade\footnote{\url{http://samate.nist.gov/index.php/SARD.html}} e o SWAMP (\textit{Software Assurance Marketplace}).

  O SARD é uma aplicação web com um banco de dados que armazena e disponibiliza, livre de cobranças, casos de teste para qualquer interessado. Para obter os casos de teste do SARD basta acessá-lo em \url{http://samate.nist.gov/SARD/}. Dentre os casos e suítes de testes disponibilizados pelo SARD, estão o Juliet, em sua versão 1.2, elaborado pelo CAS, e o STONESOUP, em sua terceira versão, elaborado pela IARPA, agência de pesquisa do governo norte-americano. O SAMATE obtém seus casos de teste para o SARD através de doações de órgãos do governo norte-americano ou de outros países, universidades, centros de pesquisa ou qualquer outra parte interessada em disponibilizar casos de teste de vulnerabilidades para as comunidades interessadas em análise estática voltada para segurança. No momento que este trabalho foi elaborado, o SARD possuía casos de teste em diferentes linguagens, incluindo C, Java e PHP.

  A suíte de testes Juliet for criada pelo CAS para que o mesmo pudesse melhor selecionar as ferramentas de análise estática para o DoD. Os resultados e metodologia desses trabalhos de seleção podem ser vistos em \cite{nsa}.

  O SWAMP é um projeto do governo norte-americano financiado pelo DHS que provê uma infraestrutura para análise estática de código fonte que inclui uma plataforma para análise estática de projetos em diferentes linguagens, casos de teste fornecidos pela comunidade (assim como o SARD, do NIST) e programas para análise estática de código fonte de licenças livres disponíveis para download. O objetivo do projeto é difundir o conhecimento e fomentar a pesquisa acerca de análise estática, além de auxiliar empresas e desenvolvedores a melhorar a qualidade de seu software, diminuindo a quantidade de bugs dos mesmos. O projeto também visa auxiliar desenvolvedores de ferramentas de análise estática, dado que provê diversos casos de teste. Toda a infraestrutura do projeto é disponibilizada de forma aberta\footnote{SWAMP: \url{continuousassurance.org} e \url{www.mir-swamp.org}}.                   

  \section{Trabalhos Correlatos}

  Embora a análise estática de código fonte não seja uma  área nova na computação – note que por definição, a própria etapa de compilação de código pode ser considerada análise estática de código – sua aplicação em segurança de código fonte é recente na academia e ainda não é consolidada na indústria \cite{johnson2013don}.

  O governo dos Estados Unidos tem investido grandes quantidades de recursos em programas de segurança da informação. O \textit{National Institute of Standards and Technology} (NIST) possui um grupo de trabalho financiado pelo departamento de segurança nacional (\textit{Department of Homeland Security} – DHS) voltado ao estudo de métricas de qualidade de software e avaliação de ferramentas (para garantia de qualidade). O SAMATE – \textit{Software Assurance Metrics And Tool Evaluation} –, como é chamado, conduz estudos em métricas de software e análise estática de código fonte. Seus dois projetos principais são o SARD e o SATE – \textit{Static Analysis Tool Exposition}, um \textit{workshop} realizado periodicamente na sede do NIST em Gaithersburg, MD nos Estados Unidos\footnote{\url{http://samate.nist.gov/SATE5Workshop.html}} que reúne indústria e academia para discutir o estado da arte de programas de análise estática de código-fonte, bem como apresentar resultados e comparações de avaliações de ferramentas de análise estática realizadas ao longo de meses pelo SAMATE (não há prazo nem uma janela de tempo específica que o SAMATE leva para analisar as ferramentas participantes do SATE, dado que tais fatores dependem do tamanho da equipe, quantidade de ferramentas avaliadas e tamanho das suítes de testes utilizadas, bem como da própria performance das ferramentas avaliadas).

  O SATE teve sua quinta edição realizada ao longo do ano de 2014 e ainda não teve (até a ocasião da escrita deste trabalho) seus resultados e artigos publicados, dado o número elevado de participantes e à inclusão de novas categorias, como a \textit{Ockham Criteria} para ferramentas de análise correta\footnote{\url{http://samate.nist.gov/SATE5OckhamCriteria.html}}. A quarta edição do SATE foi realizada em 2013 e seus resultados e artigos referentes ao mesmo podem ser obtidos no sítio do NIST\footnote{\url{http://samate.nist.gov/index.php/SAMATE_Publications.html}}.


  O MITRE, organização sem fins lucrativos que opera centros de pesquisa e desenvolvimento patrocinados pelo governo federal dos Estados Unidos, iniciou estudos de vulnerabilidade de software no ano de 1999, patrocinado pelo próprio SAMATE. Tais estudos resultaram em definições formais de vulnerabilidades conhecidas, presentes em software de produção como o Microsoft Windows\footnote{\url{http://www.cvedetails.com/vulnerability-list/vendor_id-26/product_id-26434/Microsoft-Windows-8.1.html}} e servidores web como o Apache\footnote{\url{http://www.cvedetails.com/vulnerability-list/vendor_id-45/Apache.html}}. Tal projeto é conhecido como CVE – \textit{Common Vulnerabilities and Exposures}, e pode ser acessado em \url{https://cve.mitre.org/}. O NIST também mantém uma base de dados com catálogos para as CVE, o NVD – \textit{National Vulnerability Database}, que pode ser acessado em \url{https://nvd.nist.gov/}. De uma iniciativa para atomizar e melhor compreender as vulnerabilidades definidas como CVE, o MITRE criou um projeto para definir as fraquezas de software. Estas são as CWE – \textit{Common Weakness Enumeration}. Embora haja diversos problemas com as definições de CWE \cite{yan}, não há outra definição formal comum para fraquezas de software com bons níveis de aceitação, de modo que uma mesma fraqueza pode ser apontada com diferentes descrições por diferentes ferramentas de análise estática de código fonte. Em \cite{clustering} sugere-se o uso de ferramentas para agregar relatórios relacionados a um mesmo defeito com o uso de ferramentas específicas para tal.

  É uma pratica comum que distribuições de sistemas operacionais GNU/Linux ofereçam pacotes de software para seus usuários. Sendo assim, é uma preocupação válida de seus times de garantia de qualidade que tais pacotes não contenham defeitos ou que a quantidade de defeitos em seus pacotes seja minimizada ao longo do tempo. Existem iniciativas para promover a análise estática de código fonte de tais pacotes por estes times de garantia de qualidade. Dentre elas, destacam-se o projeto Debile\footnote{\url{http://debile.debian.net/about}}, da distribuição Debian\footnote{\url{debian.org}} e o grupo de interesse em análise estática de código fonte\footnote{\url{https://fedoraproject.org/wiki/StaticAnalysis}} do projeto Fedora\footnote{\url{fedoraproject.org}}.

  O primeiro trata-se de uma ferramenta em desenvolvimento para análise de código fonte de todos os pacotes da distribuição ao longo do processo de construção dos mesmos. A ferramenta utiliza ferramentas de análise estática de código fonte de licença aberta como o flake8\footnote{\url{https://pypi.python.org/pypi/flake8}} e pylint\footnote{\url{http://www.pylint.org/}}, porém ainda não existem critérios para a seleção das ferramentas. O último consiste em um grupo de interesse com diversas iniciativas para aproximar o projeto Fedora da análise estática de código fonte. Dentre elas, destaca-se a construção de uma ferramenta para análise estática de código fonte de pacotes ao longo de testes de construção dos mesmos. Esta ferramenta é similar ao Debile, porém  apenas para construções locais, para testes das mesmas e não para produção. Nesse também não há critérios para seleção das ferramentas que realizam as análises. Ambas as ferramentas utilizam de uma mesma linguagem em comum para produzirem seus relatórios de defeitos, o firehose\footnote{\url{https://github.com/fedora-static-analysis/firehose}}. O firehose é um módulo escrito em linguagem Python pelo grupo de interesse em análise estática do projeto Fedora que define uma linguagem XML para padronização de relatórios de análise estática de código fonte.

  O CAS da NSA publicou em 2012 uma metodologia para avaliação de ferramentas de análise estática de código-fonte \cite{nsa}. Esta metodologia se assemelha ao trabalho aqui apresentado, que utiliza conceitos apresentados na mesma para generalizar métodos de avaliação de ferramentas, para que, diferente da metodologia apresentada pelo CAS, o processo seja independente de ferramentas específicas, como é o caso apresentado pelo CAS, cuja metodologia depende de suíte de testes, métricas e linguagem de saída de defeitos reportados específicas. As influências dos trabalhos apresentados pelo CAS encontradas neste trabalho se dão pelo fato de o NIST basear parte de seus trabalhos apresentados no SATE na metodologia do CAS. Note que este trabalho busca apresentar uma abordagem independente de ferramentas e linguagens, diferente dos trabalhos aqui mencionados.

